---
title: "关于爬虫"
date: 2020-04-03T14:44:50+08:00

---

# 爬虫简介
## 1. 爬虫概念
爬虫，又称网页蜘蛛或网络机器人。
爬虫是 模拟人操作客户端(浏览器，APP)  向服务器发起网络请求   抓取数据的自动化程序或脚本
  说明：
	1.模拟：用爬虫程序伪装出人的行为，避免被服务器识别为爬虫
    2.客户端：浏览器，APP都可以实现人与服务器之间交互行为，应用客户端从服务器获取数据
    3.自动化：数据量较小的时候可以人工获取，但往往在公司中爬取量在百万、千万条的所以程序要自动化

 爬虫语言：PHP, C/C++, Java, python, GOLang
 对比：
	PHP：并发能力差，对多进程和多线程，数据量较大爬虫效率较低
    C/C++：语言效率高，但学习成本高，对程序员的技术能力要求较高，所以目前还停留在研究层面，市场需求小
    Java：python爬虫的主要竞争对手，但由于Java语言特点，代码臃肿，代码量大，维护成本重构成本高，开发效率底，但目前市场上岗位需求比较旺盛
    python：语法简单，学习成本低，对新手比较友好，python语言良好的生态，大量库和框架的支持是的python爬虫目前处于爬虫圈的主导地位
    
## 2.爬虫分类

#### 1.通用爬虫：（搜索引擎）
   实列：百度、搜狗、Google的搜索引擎
   功能：访问网页 -> 抓取数据 -> 数据处理 -> 提供检索服务
   工作流：
	1.给定一个起始url，存于爬取列队中
	2.爬虫程序从队列中取出url，爬取数据
	3.解析爬取数据，获取网页内所有URL，放入爬取队列
	4.重复第二个步骤
  使搜索引擎获取网站链接：
	1.主动将URL提交给搜索引擎（https://ziyuan.baidu.com/linksubmit/url）
    2.在其他热门网站设置友情链接
    3.百度和DNS服务商合作，收录新网站
  网站排名（SEO）：
	1.根据PageRank值进行排名（流量、点击率）
    2.百度竞价排名，钱多就靠前
  缺点：
	1.抓取内容多数无用
    2.无法精准获取数据
  协议： robots协议 --> 约定那些内容允许哪些爬虫抓取
	1.无需遵守，该协议适用于通用爬虫，而我们写的是聚焦爬虫
    2.查看方法：网站url/robots.txt， 如https://www.baidu.com/robots.txt

#### 2.聚焦爬虫
   概念：聚焦爬虫指针对某一领域根据特定的要求实现爬虫程序，住区需要的数据(垂直爬虫)
   设计思路： 
	(1).确定URL， 模拟浏览器向服务器发送请求
    (2).获取响应数据并进行数据解析
    (3).讲目标数据持久化到本地